{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest model\n",
    "Use timing data produced by the GPU executable to evaluate the quality of the machine learning model. This script does the following:\n",
    "\n",
    "1. Reads timing information generated by the main executable detailing the timings of different parameter configurations. \n",
    "2. Trains a random forest model using a subset of the experiments to make predictions on execution parameters.\n",
    "3. Uses a second subset of the read experiment data to evaluate the quality of the machine learning model, i.e., how much slower the machine learning model predictions are compared to the best possible timings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from json import loads\n",
    "import pandas as pd\n",
    "\n",
    "def read_json_data_folder(input_folder):\n",
    "    all_json_objects= {}\n",
    "    for json_file_name in os.listdir(input_folder):\n",
    "        json_file_path = os.path.join(input_folder, json_file_name)\n",
    "        with open(json_file_path) as fin:\n",
    "            data = loads(fin.read())\n",
    "            all_json_objects[json_file_name] = {\n",
    "                'path': json_file_path,\n",
    "                'data': data\n",
    "            }\n",
    "    return all_json_objects\n",
    "\n",
    "def extract_df_from_json_objects(json_objects, graph_name_no_path = True):\n",
    "    df = pd.DataFrame()\n",
    "    for json_object in json_objects.values():\n",
    "        json_object = json_object['data']\n",
    "\n",
    "        metadata = json_object['metadata']\n",
    "        metadata['graph name'] = metadata['graph name']  if not graph_name_no_path else os.path.split(metadata['graph name'])[1]\n",
    "        if 'binning' in json_object['experiments'].keys():\n",
    "            binning_data = json_object['experiments']['binning']\n",
    "            ranges = binning_data['ranges']\n",
    "            kernels = list(binning_data.keys())\n",
    "            kernels.remove('ranges')\n",
    "            for kernel in kernels:\n",
    "                bins = binning_data[kernel]['bins']\n",
    "                for a_bin in bins:\n",
    "                    kernel_information =a_bin['information'] \n",
    "                    if 'b_max' not in kernel_information.keys():\n",
    "                        continue\n",
    "                    sample = {\n",
    "                        'b_max':kernel_information['b_max'],\n",
    "                        'b_min':ranges[ranges.index(kernel_information['b_max'])-1] if ranges.index(kernel_information['b_max']) != 0 else 0,\n",
    "                        'g':kernel_information['g'],\n",
    "                        'a':kernel_information['a'],\n",
    "                        'sm': 1 if kernel_information['name'].find('sm') != -1 else 0,\n",
    "                        'kernel name':kernel_information['name'],\n",
    "                        'size':a_bin['size']['first'],\n",
    "                        'time':a_bin['time'],\n",
    "                    }\n",
    "                    sample.update(metadata)\n",
    "                    sample = {key: [val] for key, val in sample.items()}\n",
    "                    df = df.append(pd.DataFrame.from_dict(sample), ignore_index=True)\n",
    "    return df\n",
    "def get_best_timings(df:pd.DataFrame, rows = ['graph name', 'b_max']):\n",
    "    filtered = df.loc[df.groupby(rows)['time'].idxmin()]\n",
    "    return filtered\n",
    "\n",
    "def remove_empty_bins(df):\n",
    "    return df[df['size']!=0]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading timing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test folders should contain experiment output JSON files generated by main executable\n",
    "train_folder = 'build/json_files/train'\n",
    "test_folder = 'build/json_files/test'\n",
    "\n",
    "train_json_objects = read_json_data_folder(train_folder)\n",
    "test_json_objects = read_json_data_folder(test_folder)\n",
    "\n",
    "train_df = extract_df_from_json_objects(train_json_objects)\n",
    "test_df = extract_df_from_json_objects(test_json_objects)\n",
    "\n",
    "train_df = remove_empty_bins(train_df)\n",
    "test_df = remove_empty_bins(test_df)\n",
    "\n",
    "# the training set contains only the parameters resulting in the best timings\n",
    "train_df = get_best_timings(train_df)\n",
    "\n",
    "# This is the best kernel for each bin on each test graph\n",
    "# will be used as ground truth when evaluating\n",
    "test_oracle_df  = get_best_timings(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training random forest model and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['b_max', 'b_min', 'size', 'avg_deg','max_deg']\n",
    "label_columns = ['g', 'a', 'sm']\n",
    "\n",
    "X_train, Y_train = train_df[feature_columns], train_df[label_columns]\n",
    "# Train the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dt = RandomForestClassifier(criterion = 'entropy', random_state = 42)\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "# get the features of each bin in each test graph\n",
    "features_to_test = test_oracle_df[feature_columns+[\"graph name\"]]\n",
    "# predict the values for each bin on each test graph\n",
    "predictions = dt.predict(features_to_test[feature_columns])\n",
    "# Get the timings of the predicted labels for each bin for each graph\n",
    "predictions_and_graphs = features_to_test[['graph name', 'b_max']]\n",
    "for i, label in enumerate(label_columns):\n",
    "    predictions_and_graphs = predictions_and_graphs.assign(**{label : predictions[:, i]})\n",
    "predictions_and_graphs[\"time\"] = predictions_and_graphs.apply(lambda x: test_df[(test_df['graph name'] == x['graph name']) & (test_df['b_max'] == x['b_max']) & (test_df['g'] == x['g']) & (test_df['a'] == x['a']) & (test_df['sm'] == x['sm'])].iloc[0]['time'], axis = 1)\n",
    "# compare to ground truth\n",
    "for graph in predictions_and_graphs['graph name'].unique():\n",
    "    graph_best_timings = test_oracle_df[test_oracle_df['graph name'] == graph][['b_max', 'time']]\n",
    "    graph_predicted_timings = predictions_and_graphs[predictions_and_graphs['graph name'] == graph][['b_max', 'time']]\n",
    "    loss = 0\n",
    "    total_best_time = 0\n",
    "    total_predicted_time = 0\n",
    "    for b_max in graph_best_timings['b_max'].unique():\n",
    "        best_time = graph_best_timings[graph_best_timings['b_max'] == b_max]['time'].iloc[0]\n",
    "        predicted_time = graph_predicted_timings[graph_predicted_timings['b_max'] == b_max]['time'].iloc[0]\n",
    "        total_best_time+=best_time\n",
    "        total_predicted_time+=predicted_time\n",
    "        loss+=predicted_time-best_time\n",
    "    print(\"Graph\", graph)\n",
    "    print(\"Best time =\", \"{:.3f}\".format(total_best_time), \"Predicted time =\", \"{:.3f}\".format(total_predicted_time), \"Slowdown % =\", \"{:.2f}\".format((total_predicted_time-total_best_time)/total_best_time*100)+\"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8c1f25291ef65d8be01f9370db0577cbeebbe1721e744b06cf27639a870e3bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
